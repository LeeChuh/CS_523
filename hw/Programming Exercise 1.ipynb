{"cells":[{"cell_type":"markdown","id":"f490e512","metadata":{"id":"f490e512"},"source":["Programming Exercise 1\n","==========\n","\n","<b>Topics</b>: CNN, RNN, GNN\n","\n","<b>Due Date</b>: October 21th, Friday 11:59PM\n","\n","Read the instructions below and fill in the code where indicated.\n","\n","The overall goal for this exercise is to understand architectures where weights are shared across space, time or to messages in a graph structure. As you are going through this exercise, try to (a) understand why a new architecture is needed, i.e. why we can't just use a feed-forward NN for everything; and (b) intuit the failure modes of a particular architecture, e.g., would a CNN stumble with image generation."]},{"cell_type":"markdown","id":"bb5e7c9c","metadata":{"id":"bb5e7c9c"},"source":["Part 1. Convolutional Neural Networks in Keras\n","--------------------\n","Implement and **RUN** a CNN in Keras using convolutional layers, dense layers, dropout, max pooling.\n","\n","\n","The inputs are 32x32 images passed as standard three-channel color so the shape of the inputs is [32, 32, 3]. Create a CNN that achieves greater than 75% validation accuracy.\n","\n","\n","Here are some components to get you started. Plot your training and validation accuracies and report the final validation accuracy score.\n","The portions you will complete can be located with “TO DO”."]},{"cell_type":"code","execution_count":1,"id":"991fc40a","metadata":{"id":"991fc40a"},"outputs":[],"source":["from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.constraints import maxnorm\n","from tensorflow.keras.optimizers import SGD\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.utils import np_utils"]},{"cell_type":"code","execution_count":2,"id":"af4123cc","metadata":{"id":"af4123cc"},"outputs":[],"source":["# load data\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","# normalize inputs from 0-255 to 0.0-1.0\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","# one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","num_classes = y_test.shape[1]"]},{"cell_type":"code","execution_count":3,"id":"YwUfh_cuL78W","metadata":{"id":"YwUfh_cuL78W"},"outputs":[{"name":"stdout","output_type":"stream","text":["Metal device set to: Apple M1 Max\n","\n","systemMemory: 64.00 GB\n","maxCacheSize: 24.00 GB\n","\n"]},{"name":"stderr","output_type":"stream","text":["2022-10-09 22:09:26.859617: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2022-10-09 22:09:26.859729: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]}],"source":["# CNN model specification\n","\n","'''\n","TO DO: Define your CNN model here with convolutional layers, dense layers, dropout, max pooling\n","'''\n","model = Sequential([\n","    Conv2D(32, (5, 5), activation='relu', input_shape = (32, 32, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (5, 5), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dropout(0.5),\n","    Dense(128),\n","    Dropout(0.5),\n","    Dense(64),\n","    Dropout(0.5),\n","    Dense(10, activation='softmax')\n","])\n","\n"]},{"cell_type":"code","execution_count":4,"id":"bBrZX1EeNKUy","metadata":{"id":"bBrZX1EeNKUy"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 32)        2432      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 10, 10, 64)        51264     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 1600)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 1600)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               204928    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 267,530\n","Trainable params: 267,530\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n"]},{"name":"stderr","output_type":"stream","text":["2022-10-09 22:09:27.314129: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n","2022-10-09 22:09:27.552364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["782/782 [==============================] - ETA: 0s - loss: 1.9894 - accuracy: 0.2527"]},{"name":"stderr","output_type":"stream","text":["2022-10-09 22:09:38.590065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["782/782 [==============================] - 12s 15ms/step - loss: 1.9894 - accuracy: 0.2527 - val_loss: 1.6718 - val_accuracy: 0.3987\n","Epoch 2/25\n","647/782 [=======================>......] - ETA: 1s - loss: 1.6889 - accuracy: 0.3766"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/chuhanli/Documents/GitHub/CS_523/hw/Programming Exercise 1.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chuhanli/Documents/GitHub/CS_523/hw/Programming%20Exercise%201.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chuhanli/Documents/GitHub/CS_523/hw/Programming%20Exercise%201.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chuhanli/Documents/GitHub/CS_523/hw/Programming%20Exercise%201.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chuhanli/Documents/GitHub/CS_523/hw/Programming%20Exercise%201.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Final evaluation of the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chuhanli/Documents/GitHub/CS_523/hw/Programming%20Exercise%201.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1414\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1416\u001b[0m   \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 607\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    599\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 601\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    602\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# CNN model training\n","\n","'''\n","Run the training prompt below. Feel free to modify the training pipeline\n","Batch size might need some tuning depending on your architecture, but 64 was found to be good for a large CNN\n","'''\n","\n","epochs = 100\n","lrate = 0.01\n","decay = lrate/epochs\n","sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","model.summary()\n","\n","# Fit the model\n","\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n","\n","# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"]},{"cell_type":"markdown","id":"iOh_y-OPZlWf","metadata":{"id":"iOh_y-OPZlWf"},"source":["Part 2. Recurrent Neural Networks in PyTorch\n","--------------------\n","Implement and **RUN** a RNN in PyTorch.\n","\n","Download and unzip this [folder](https://download.pytorch.org/tutorial/data.zip) to your current directory.\n","\n","Define a RNN architecture to be used in this code block for character-by-character analysis of names to predict nationality of the individual.\n","\n","The portions you will complete can be located with “TO DO”."]},{"cell_type":"code","execution_count":null,"id":"pEvP9DkIZudp","metadata":{"id":"pEvP9DkIZudp"},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import glob\n","import os\n","\n","def findFiles(path):\n","  return glob.glob(path)\n","\n","# change this to your current directory path if you need\n","print(findFiles('/content/drive/MyDrive/Colab Notebooks/data/*.txt'))\n","\n","import unicodedata\n","import string\n","\n","all_letters = string.ascii_letters + \" .,;'\"\n","n_letters = len(all_letters)\n","\n","# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","        and c in all_letters\n","    )\n","\n","print(unicodeToAscii('Ślusàrski'))\n","\n","# Build the category_lines dictionary, a list of names per language\n","category_lines = {}\n","all_categories = []\n","\n","# Read a file and split into lines\n","def readLines(filename):\n","    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n","    return [unicodeToAscii(line) for line in lines]\n","\n","for filename in findFiles('/content/drive/MyDrive/Colab Notebooks/data/*.txt'):\n","    category = os.path.splitext(os.path.basename(filename))[0]\n","    all_categories.append(category)\n","    lines = readLines(filename)\n","    category_lines[category] = lines\n","\n","n_categories = len(all_categories)"]},{"cell_type":"code","execution_count":null,"id":"QMq2fzOqciRe","metadata":{"id":"QMq2fzOqciRe"},"outputs":[],"source":["print(category_lines['Italian'][:5])"]},{"cell_type":"code","execution_count":null,"id":"5XrNoq_serN0","metadata":{"id":"5XrNoq_serN0"},"outputs":[],"source":["# Turning names into tensors\n","\n","import torch\n","\n","# Find letter index from all_letters, e.g. \"a\" = 0\n","def letterToIndex(letter):\n","    return all_letters.find(letter)\n","\n","# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n","def letterToTensor(letter):\n","    tensor = torch.zeros(1, n_letters)\n","    tensor[0][letterToIndex(letter)] = 1\n","    return tensor\n","\n","# Turn a line into a <line_length x 1 x n_letters>,\n","# or an array of one-hot letter vectors\n","def lineToTensor(line):\n","    tensor = torch.zeros(len(line), 1, n_letters)\n","    for li, letter in enumerate(line):\n","        tensor[li][0][letterToIndex(letter)] = 1\n","    return tensor\n","\n","print(letterToTensor('J'))\n","\n","print(lineToTensor('Jones').size())"]},{"cell_type":"markdown","id":"OG3pjLizos5c","metadata":{"id":"OG3pjLizos5c"},"source":["![RNN_Sample.png](data:image/png;base64,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)"]},{"cell_type":"code","execution_count":null,"id":"VgrDTyw1gB4s","metadata":{"id":"VgrDTyw1gB4s"},"outputs":[],"source":["import torch.nn as nn\n","\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(RNN, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","\n","        '''\n","        TO DO:\n","        Define your layers and activation function here, according to the recommended architecture above.\n","        Hint: you only need to define the blue (LINEAR) and green (ACTIVATION) layers\n","        '''\n","\n","    def forward(self, input, hidden):\n","        '''\n","        TO DO:\n","        Define your forward pass.\n","        Hint: follow the arrows.\n","        '''\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, self.hidden_size)\n","\n","n_hidden = 128\n","rnn = RNN(n_letters, n_hidden, n_categories)"]},{"cell_type":"markdown","id":"7LjN3EidmCy2","metadata":{"id":"7LjN3EidmCy2"},"source":["To run a step of this network we need to pass an input (in our case, the Tensor for the current letter) and a previous hidden state (which we initialize as zeros at first). We’ll get back the output (probability of each language) and a next hidden state (which we keep for the next step)."]},{"cell_type":"code","execution_count":null,"id":"RmUQtE8yl4gS","metadata":{"id":"RmUQtE8yl4gS"},"outputs":[],"source":["input = letterToTensor('A')\n","hidden = torch.zeros(1, n_hidden)\n","\n","output, next_hidden = rnn(input, hidden)"]},{"cell_type":"markdown","id":"pRXz7mT0mHyo","metadata":{"id":"pRXz7mT0mHyo"},"source":["For the sake of efficiency we don’t want to be creating a new Tensor for every step, so we will use lineToTensor instead of letterToTensor and use slices. This could be further optimized by pre-computing batches of Tensors."]},{"cell_type":"code","execution_count":null,"id":"oVJ01_JmmG6E","metadata":{"id":"oVJ01_JmmG6E"},"outputs":[],"source":["input = lineToTensor('Albert')\n","hidden = torch.zeros(1, n_hidden)\n","\n","output, next_hidden = rnn(input[0], hidden)\n","print(output)"]},{"cell_type":"code","execution_count":null,"id":"Rale2Ij4mJr5","metadata":{"id":"Rale2Ij4mJr5"},"outputs":[],"source":["# Helper functions\n","\n","'''\n","Here we interpret the output of the network, which we know to be a likelihood of each category.\n","We can use Tensor.topk to get the index of the greatest value\n","'''\n","\n","def categoryFromOutput(output):\n","    top_n, top_i = output.topk(1)\n","    category_i = top_i[0].item()\n","    return all_categories[category_i], category_i\n","\n","print(categoryFromOutput(output))\n","\n","\n","'''\n","Quickly get training example\n","'''\n","import random\n","\n","def randomChoice(l):\n","    return l[random.randint(0, len(l) - 1)]\n","\n","def randomTrainingExample():\n","    category = randomChoice(all_categories)\n","    line = randomChoice(category_lines[category])\n","    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n","    line_tensor = lineToTensor(line)\n","    return category, line, category_tensor, line_tensor\n","\n","for i in range(10):\n","    category, line, category_tensor, line_tensor = randomTrainingExample()\n","    print('category =', category, '/ line =', line)"]},{"cell_type":"code","execution_count":null,"id":"mODNjPigmQgs","metadata":{"id":"mODNjPigmQgs"},"outputs":[],"source":["'''\n","TO DO:\n","Define your loss function based on the activation layer of your RNN\n","'''\n","criterion = "]},{"cell_type":"code","execution_count":null,"id":"1A_bJzrUm40H","metadata":{"id":"1A_bJzrUm40H"},"outputs":[],"source":["# Training block\n","\n","learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n","\n","def train(category_tensor, line_tensor):\n","    hidden = rnn.initHidden()\n","\n","    rnn.zero_grad()\n","\n","    for i in range(line_tensor.size()[0]):\n","        output, hidden = rnn(line_tensor[i], hidden)\n","\n","    loss = criterion(output, category_tensor)\n","    loss.backward()\n","\n","    # Add parameters' gradients to their values, multiplied by learning rate\n","    for p in rnn.parameters():\n","        p.data.add_(p.grad.data, alpha=-learning_rate)\n","\n","    return output, loss.item()\n","\n","\n","import time\n","import math\n","\n","n_iters = 100000\n","print_every = 5000\n","plot_every = 1000\n","\n","# Keep track of losses for plotting\n","current_loss = 0\n","all_losses = []\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","start = time.time()\n","\n","for iter in range(1, n_iters + 1):\n","    category, line, category_tensor, line_tensor = randomTrainingExample()\n","    output, loss = train(category_tensor, line_tensor)\n","    current_loss += loss\n","\n","    # Print iter number, loss, name and guess\n","    if iter % print_every == 0:\n","        guess, guess_i = categoryFromOutput(output)\n","        correct = '✓' if guess == category else '✗ (%s)' % category\n","        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n","\n","    # Add current loss avg to list of losses\n","    if iter % plot_every == 0:\n","        all_losses.append(current_loss / plot_every)\n","        current_loss = 0"]},{"cell_type":"code","execution_count":null,"id":"re2wmT4vnAZE","metadata":{"id":"re2wmT4vnAZE"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","plt.figure()\n","plt.plot(all_losses)"]},{"cell_type":"code","execution_count":null,"id":"ixHdLaeNngIp","metadata":{"id":"ixHdLaeNngIp"},"outputs":[],"source":["# Evaluating the results\n","\n","# Keep track of correct guesses in a confusion matrix\n","confusion = torch.zeros(n_categories, n_categories)\n","n_confusion = 10000\n","\n","# Just return an output given a line\n","def evaluate(line_tensor):\n","    hidden = rnn.initHidden()\n","\n","    for i in range(line_tensor.size()[0]):\n","        output, hidden = rnn(line_tensor[i], hidden)\n","\n","    return output\n","\n","# Go through a bunch of examples and record which are correctly guessed\n","for i in range(n_confusion):\n","    category, line, category_tensor, line_tensor = randomTrainingExample()\n","    output = evaluate(line_tensor)\n","    guess, guess_i = categoryFromOutput(output)\n","    category_i = all_categories.index(category)\n","    confusion[category_i][guess_i] += 1\n","\n","# Normalize by dividing every row by its sum\n","for i in range(n_categories):\n","    confusion[i] = confusion[i] / confusion[i].sum()\n","\n","# Set up plot\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","cax = ax.matshow(confusion.numpy())\n","fig.colorbar(cax)\n","\n","# Set up axes\n","ax.set_xticklabels([''] + all_categories, rotation=90)\n","ax.set_yticklabels([''] + all_categories)\n","\n","# Force label at every tick\n","ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","# sphinx_gallery_thumbnail_number = 2\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"PPM3JzjqnlpT","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPM3JzjqnlpT","outputId":"c6c17a7e-7003-49c3-8dea-8e7c2903111f"},"outputs":[],"source":["# Test it yourself\n","\n","def predict(input_line, n_predictions=3):\n","    print('\\n> %s' % input_line)\n","    with torch.no_grad():\n","        output = evaluate(lineToTensor(input_line))\n","\n","        # Get top N categories\n","        topv, topi = output.topk(n_predictions, 1, True)\n","        predictions = []\n","\n","        for i in range(n_predictions):\n","            value = topv[0][i].item()\n","            category_index = topi[0][i].item()\n","            print('(%.2f) %s' % (value, all_categories[category_index]))\n","            predictions.append([value, all_categories[category_index]])\n","\n","predict('Dostoevsky')\n","predict('Martineau')\n","predict('Papadimitriou')"]},{"cell_type":"markdown","id":"cuQahPZiqZiL","metadata":{"id":"cuQahPZiqZiL"},"source":["Part 3. Graph Neural Networks in DGL\n","--------------------\n","\n","Adapt from Tutorial 4 on the DGL library for Graph Neural Networks to a new dataset: CORA (refer to documentation [here](https://relational.fit.cvut.cz/dataset/CORA)). Your goal is to classify the nodes in this research paper dataset.\n","\n","Fill in the TO DO parts where the code is missing, to define your GNN architecture. This requires you to reason about the dimensionality of the features and labels in this problem."]},{"cell_type":"code","execution_count":null,"id":"BZj0UbnxXHee","metadata":{"id":"BZj0UbnxXHee"},"outputs":[],"source":["import dgl\n","import dgl.function as fn\n","import torch as th\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dgl import DGLGraph\n","\n","gcn_msg = fn.copy_u(u='h', out='m')\n","gcn_reduce = fn.sum(msg='m', out='h')"]},{"cell_type":"code","execution_count":null,"id":"CR_HCoNNXLSQ","metadata":{"id":"CR_HCoNNXLSQ"},"outputs":[],"source":["class GCNLayer(nn.Module):\n","    def __init__(self, in_feats, out_feats):\n","        super(GCNLayer, self).__init__()\n","        \"\"\"\n","        TO DO:\n","        Define a single Linear layer here\n","        \"\"\"\n","\n","    def forward(self, g, feature):\n","        # Creating a local scope so that all the stored ndata and edata\n","        # (such as the `'h'` ndata below) are automatically popped out\n","        # when the scope exits.\n","        with g.local_scope():\n","            \"\"\"\n","            TO DO:\n","            Define the forward pass to pass and accummulate messages\n","            \"\"\"\n","            return self.linear(h)"]},{"cell_type":"code","execution_count":null,"id":"MkS9IQZSXXk6","metadata":{"id":"MkS9IQZSXXk6"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \"\"\"\n","        Define 2 layers of the GCNLayer type you just coded above.\n","        Refer to the documentation of the CORA dataset (https://relational.fit.cvut.cz/dataset/CORA):\n","        what should be the input dimension of each node's vector?\n","        what should be the final output dimension for this classification task?\n","        \"\"\"\n","    \n","    def forward(self, g, features):\n","        \"\"\"\n","        Define your forward pass with a ReLU activation between the 2 layers\n","        \"\"\"\n","        return x\n","\n","net = Net()\n","print(net)"]},{"cell_type":"code","execution_count":null,"id":"mXZRQSx3uRhy","metadata":{"id":"mXZRQSx3uRhy"},"outputs":[],"source":["# CORA dataset (https://relational.fit.cvut.cz/dataset/CORA)\n","\n","from dgl.data import CoraGraphDataset\n","def load_cora_data():\n","    dataset = CoraGraphDataset()\n","    g = dataset[0]\n","    features = g.ndata['feat']\n","    labels = g.ndata['label']\n","    train_mask = g.ndata['train_mask']\n","    test_mask = g.ndata['test_mask']\n","    return g, features, labels, train_mask, test_mask\n","\n","# Helper function to evaluate performance\n","\n","def evaluate(model, g, features, labels, mask):\n","model.eval()\n","with th.no_grad():\n","    logits = model(g, features)\n","    logits = logits[mask]\n","    labels = labels[mask]\n","    _, indices = th.max(logits, dim=1)\n","    correct = th.sum(indices == labels)\n","    return correct.item() * 1.0 / len(labels)"]},{"cell_type":"markdown","id":"GWnKPeZBxQ4V","metadata":{"id":"GWnKPeZBxQ4V"},"source":["If your code above is correct, when you run the training loop below you should see loss decrease, and test accuracy increase."]},{"cell_type":"code","execution_count":null,"id":"9jvktGkfuUb7","metadata":{"id":"9jvktGkfuUb7"},"outputs":[],"source":["# Training loop\n","\n","import time\n","import numpy as np\n","g, features, labels, train_mask, test_mask = load_cora_data()\n","# Add edges between each node and itself to preserve old node representations\n","g.add_edges(g.nodes(), g.nodes())\n","optimizer = th.optim.Adam(net.parameters(), lr=1e-2)\n","dur = []\n","for epoch in range(50):\n","    if epoch >=3:\n","        t0 = time.time()\n","\n","    net.train()\n","    logits = net(g, features)\n","    logp = F.log_softmax(logits, 1)\n","    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if epoch >=3:\n","        dur.append(time.time() - t0)\n","    \n","    acc = evaluate(net, g, features, labels, test_mask)\n","    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n","            epoch, loss.item(), acc, np.mean(dur)))"]},{"cell_type":"markdown","id":"jW-z5ntmxkly","metadata":{"id":"jW-z5ntmxkly"},"source":["Mathematically, the GCN model follows this formula:\n","\n","$H^{(l+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)})$\n","\n","Here, $H^{(l)}$ denotes the $l^{th}$ layer in the network,\n","$\\sigma$ is the non-linearity, and $W$ is the weight matrix for\n","this layer. $\\tilde{D}$ and $\\tilde{A}$ are separately the degree\n","and adjacency matrices for the graph. With the superscript ~, we are referring\n","to the variant where we add additional edges between each node and itself to\n","preserve its old representation in graph convolutions. The shape of the input\n","$H^{(0)}$ is $N \\times D$, where $N$ is the number of nodes\n","and $D$ is the number of input features. We can chain up multiple\n","layers as such to produce a node-level representation output with shape\n","$N \\times F$, where $F$ is the dimension of the output node\n","feature vector."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":5}
